{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq96k-Sq_zUn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.PyTorch의 기본 개념을 이해하고, 텐서 연산, 자동 미분, 간단한 신경망 모델을 구현해보기"
      ],
      "metadata": {
        "id": "Wye32ajRCVI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3])  # 1D 텐서 생성\n",
        "y = torch.ones(2, 3)         # 모든 값이 1인 2x3 텐서 생성\n",
        "z = torch.zeros(4, 5)        # 모든 값이 0인 4x5 텐서 생성\n",
        "\n",
        "print(\"X: \", x)\n",
        "print(\"Y: \", y)\n",
        "print(\"Z: \", z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRo0pGFRCWoO",
        "outputId": "6e82477d-8933-4669-d138-40cf7169f4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:  tensor([1, 2, 3])\n",
            "Y:  tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Z:  tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 속성\n",
        "print(x.shape)  # 텐서의 형태\n",
        "print(y.size()) # 텐서의 크기\n",
        "print(z.dtype)  # 텐서의 데이터 타입"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YEyGHCcDY2P",
        "outputId": "a635f428-d8be-405d-9e38-bb288ac1445b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([2, 3])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본연산\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "c = a + b  # 텐서 덧셈\n",
        "d = a * b  # 텐서 곱셈\n",
        "\n",
        "print(\"덧셈 결과:\", c)\n",
        "print(\"곱셈 결과:\", d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3qi6pETDeEF",
        "outputId": "c39b97fc-7b14-4101-d5a1-d3e2cd71cb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "덧셈 결과: tensor([5, 7, 9])\n",
            "곱셈 결과: tensor([ 4, 10, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 행렬 연산\n",
        "A = torch.tensor([[1, 2], [3, 4]])\n",
        "B = torch.tensor([[5, 6], [7, 8]])\n",
        "C = torch.matmul(A, B) # 행렬 곱셈\n",
        "\n",
        "print(\"행렬 곱셈 결과:\\n\", C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJO2IYHzDg4O",
        "outputId": "89b88d4b-e42d-4e44-db5a-6a3e7d1dc974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "행렬 곱셈 결과:\n",
            " tensor([[19, 22],\n",
            "        [43, 50]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 크기가 3x3인 랜덤 텐서 생성\n",
        "x = torch.rand(3, 3)\n",
        "y = torch.rand(3, 3)\n",
        "\n",
        "# 텐서의 합계\n",
        "z = torch.sum(x)\n",
        "print(\"합계:\\n\", z)\n",
        "\n",
        "# 텐서의 최대값과 인덱스\n",
        "z, idx = torch.max(x, dim=0)\n",
        "print(\"최대값:\\n\", z)\n",
        "print(\"최대값 인덱스:\\n\", idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggKl1sbeEfdf",
        "outputId": "73cd70aa-2974-4bc1-88af-2bf0cf304e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "합계:\n",
            " tensor(3.9603)\n",
            "최대값:\n",
            " tensor([0.8913, 0.5515, 0.6820])\n",
            "최대값 인덱스:\n",
            " tensor([1, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 연산의 Broadcasting\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([[1], [2], [3]])\n",
        "z = x + y\n",
        "\n",
        "print(\"x의 덧셈 결과:\\n\", x)\n",
        "print(\"y의 덧셈 결과:\\n\", y)\n",
        "print(\"z의 덧셈 결과:\\n\", z)\n",
        "print(\"x의 형태:\", x.shape)\n",
        "print(\"y의 형태:\", y.shape)\n",
        "print(\"z의 형태:\", z.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC-1GLihFbq-",
        "outputId": "8001efc9-331d-41bc-cdcb-e3f09949c271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x의 덧셈 결과:\n",
            " tensor([1, 2, 3])\n",
            "y의 덧셈 결과:\n",
            " tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "z의 덧셈 결과:\n",
            " tensor([[2, 3, 4],\n",
            "        [3, 4, 5],\n",
            "        [4, 5, 6]])\n",
            "x의 형태: torch.Size([3])\n",
            "y의 형태: torch.Size([3, 1])\n",
            "z의 형태: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- x의 형태: torch.Size([3]) - [가로]\n",
        "- y의 형태: torch.Size([3, 1]) - [세로, 가로]\n",
        "- z의 형태: torch.Size([3, 3])"
      ],
      "metadata": {
        "id": "4rEGEjlBGUdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 자동 미분 (Autograd), autograd 모듈은 역전파를 통해 자동으로 기울기를 계산\n",
        "\n",
        "x = torch.tensor([1.0, 3.0, 5.0], requires_grad=True)\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "out.backward() # 역전파 수행\n",
        "print(x.grad) # x에 데한 기울기 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExtkF3gdG2Vl",
        "outputId": "fe725a33-938d-4db2-fcee-c6b51d13dee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 6., 10., 14.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "out = z.mean()\n",
        "\n",
        "out의 z에 대한 기울기: dout/dz = 1/3, 즉 각 요소에 대해 1/3.\n",
        "z = 3 * y^2\n",
        "\n",
        "z의 y에 대한 기울기: dz/dy = 6y.\n",
        "y = x + 2\n",
        "\n",
        "y의 x에 대한 기울기: dy/dx = 1.\n",
        "따라서 x에 대한 기울기는 다음과 같이 계산됩니다.\n",
        "\n",
        "dz/dx = dz/dy * dy/dx = 6y * 1 = 6y.\n",
        "dout/dx = dout/dz * dz/dy * dy/dx = (1/3) * 6y.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "L4-7VZnAIUkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- z의 평균을 계산. 따라서 out의 값은 (27.0 + 75.0 + 147.0) / 3 = 83.0\n",
        "- x[0]에 대한 기울기:\n",
        "- y[0] = 3.0, 따라서 dz/dx[0] = 6 * 3.0 = 18.0.\n",
        "- dout/dx[0] = (1/3) * 18.0 = 6.0.\n",
        "\n",
        "\n",
        "- x[1]에 대한 기울기:\n",
        "- y[1] = 5.0, 따라서 dz/dx[1] = 6 * 5.0 = 30.0.\n",
        "- dout/dx[1] = (1/3) * 30.0 = 10.0.\n",
        "\n",
        "\n",
        "- x[2]에 대한 기울기:\n",
        "- y[2] = 7.0, 따라서 dz/dx[2] = 6 * 7.0 = 42.0.\n",
        "- dout/dx[2] = (1/3) * 42.0 = 14.0.\n",
        "\n",
        "따라서 x.grad는 [6.0, 10.0, 14.0]가 됩니다."
      ],
      "metadata": {
        "id": "jXFO-x2wHn9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad=True를 설정하여 텐서의 기울기를 계산하도록 지정\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# 함수 정의\n",
        "z = x * y + y**2\n",
        "\n",
        "# 역전파 수행\n",
        "z.backward()\n",
        "\n",
        "# 기울기 출력\n",
        "print(\"x에 대한 기울기:\", x.grad)\n",
        "print(\"y에 대한 기울기:\", y.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFZzpj0QIfZl",
        "outputId": "aa8bcec1-6611-49d3-b3e2-a3ad36b1a591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x에 대한 기울기: tensor(3.)\n",
            "y에 대한 기울기: tensor(8.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- x에 데한 편미분: y^2는 독립적. x만 계산\n",
        "- y에 데한 편미분: x + 2y"
      ],
      "metadata": {
        "id": "I7rjnMbAJPPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 모듈 (nn.Module),  nn.Module은 신경망의 기본 모듈\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self): # 신경망의 계층을 정의하는 부분\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x): # 순전파를 정의하는 부분으로, 입력 데이터가 신경망을 통과하는 방식을 지정\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maC4bwRJJggB",
        "outputId": "5d34ac3f-1140-4eb7-e83c-441b7e3addc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # 첫 번째 합성곱 층\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)  # 배치 정규화\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # 최대 풀링\n",
        "        self.dropout1 = nn.Dropout(p=0.25)  # 드롭아웃\n",
        "\n",
        "        # 두 번째 합성곱 층\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)  # 배치 정규화\n",
        "        self.dropout2 = nn.Dropout(p=0.25)  # 드롭아웃\n",
        "\n",
        "        # 세 번째 합성곱 층\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)  # 배치 정규화\n",
        "        self.dropout3 = nn.Dropout(p=0.25)  # 드롭아웃\n",
        "\n",
        "        # 네 번쨰 합성곱 층\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)  # 배치 정규화\n",
        "        self.dropout4 = nn.Dropout(p=0.25)  # 드롭아웃\n",
        "\n",
        "        # 완전 연결 층\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n",
        "        self.bn5 = nn.BatchNorm1d(256)  # 배치 정규화\n",
        "        self.dropout5 = nn.Dropout(p=0.5)  # 드롭아웃\n",
        "        self.fc5 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.dropout3(x)\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = x.view(-1, 64 * 7 * 7)  # 평탄화\n",
        "        x = self.pool(F.relu(self.bn5(self.fc1(x))))\n",
        "\n",
        "        x = self.dropout5(x)\n",
        "        x = self.fc5(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# 모델 초기화\n",
        "model_cnn = CNN()\n",
        "print(model_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vjvLvbQMklv",
        "outputId": "0705b1f5-dc32-43e3-cb89-74bc112fa95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout2): Dropout(p=0.25, inplace=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout3): Dropout(p=0.25, inplace=False)\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout4): Dropout(p=0.25, inplace=False)\n",
            "  (fc1): Linear(in_features=3136, out_features=256, bias=True)\n",
            "  (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout5): Dropout(p=0.5, inplace=False)\n",
            "  (fc5): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. 간단한 Seq2Seq 모델 구현해보기 - 1"
      ],
      "metadata": {
        "id": "aqcbmsTAPtwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, emb_size, hidden_size, num_layers, dropout_p=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, emb_size)\n",
        "        self.rnn = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True, dropout=dropout_p)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # 임베딩 후 드롭아웃 적용\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # LSTM에 임베딩 벡터 입력\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        # 은닉 상태와 셀 상태 반환\n",
        "        return hidden, cell\n"
      ],
      "metadata": {
        "id": "zyb8J3iNPxKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, emb_size, hidden_size, num_layers, dropout_p=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, emb_size)  # 임베딩 층 정의\n",
        "        self.rnn = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True)  # LSTM 층 정의\n",
        "        self.fc_out = nn.Linear(hidden_size, output_size)  # 완전 연결 층 정의\n",
        "        self.dropout = nn.Dropout(dropout_p)  # 드롭아웃 정의\n",
        "\n",
        "    def forward(self, trg, hidden, cell):\n",
        "        trg = trg.unsqueeze(1)  # trg 형태: [배치 크기, 1]\n",
        "        embedded = self.dropout(self.embedding(trg))  # 임베딩 후 드롭아웃 적용, embedded 형태: [배치 크기, 1, emb_size]\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))  # LSTM 적용, output 형태: [배치 크기, 1, hidden_size]\n",
        "        predictions = self.fc_out(output.squeeze(1))  # 예측값 계산, predictions 형태: [배치 크기, output_size]\n",
        "        return predictions, hidden, cell  # 예측값과 새로운 은닉 상태, 셀 상태 반환\n"
      ],
      "metadata": {
        "id": "NYj6vbDRTAoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, forcing_ratio=0.5):\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = src.shape[1]\n",
        "        trg_vocab_size = self.decoder.embedding.num_embeddings\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # 인코더를 통해 입력 시퀀스를 은닉 상태와 셀 상태로 변환\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # 첫 입력은 항상 <sos> 토큰 (시작 토큰)\n",
        "        input = trg[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # 디코더를 통해 출력 계산\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "\n",
        "            # teacher forcing 결정\n",
        "            teacher_force = random.random() < forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            # 다음 입력을 teacher forcing에 따라 결정\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "OHUkkGW0U1Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "INPUT_DIM = 1000\n",
        "OUTPUT_DIM = 1000\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5"
      ],
      "metadata": {
        "id": "cyEH4bCQWjO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 및 디코더 모델 정의\n",
        "encoder = Encoder(input_size=INPUT_DIM, emb_size=ENC_EMB_DIM, hidden_size=HID_DIM, num_layers=N_LAYERS, dropout_p=ENC_DROPOUT)\n",
        "decoder = Decoder(output_size=OUTPUT_DIM, emb_size=DEC_EMB_DIM, hidden_size=HID_DIM, num_layers=N_LAYERS, dropout_p=DEC_DROPOUT)\n",
        "\n",
        "# Seq2Seq 모델 정의\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_1 = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "# 모델 구조 출력\n",
        "print(model_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZXFmiHGWbJx",
        "outputId": "623185bb-c12d-4931-ead7-a5d478c9744b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Embedding(1000, 256)\n",
            "    (rnn): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (embedding): Embedding(1000, 256)\n",
            "    (rnn): LSTM(256, 512, num_layers=2, batch_first=True)\n",
            "    (fc_out): Linear(in_features=512, out_features=1000, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. 간단한 Seq2Seq 모델 구현해보기 - 2"
      ],
      "metadata": {
        "id": "zDc-ZYN2Vp3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "INPUT_DIM = 1000  # 입력 단어의 개수 (어휘 크기)\n",
        "OUTPUT_DIM = 1000  # 출력 단어의 개수 (어휘 크기)\n",
        "HID_DIM = 512  # LSTM의 은닉 상태 크기\n",
        "N_LAYERS = 2  # LSTM 레이어 수\n",
        "ENC_DROPOUT = 0.5  # 인코더 드롭아웃 비율\n",
        "DEC_DROPOUT = 0.5  # 디코더 드롭아웃 비율\n",
        "MAX_LENGTH = 10  # 최대 시퀀스 길이\n",
        "SOS_token = 1  # 시작 토큰 인덱스"
      ],
      "metadata": {
        "id": "9tefJEwZYCoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # 임베딩 층: 단어를 임베딩 벡터로 변환\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # LSTM 층: 임베딩 벡터를 입력으로 받아 인코딩\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # 드롭아웃: 과적합 방지를 위해 임베딩 벡터에 드롭아웃 적용\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # 입력 시퀀스를 임베딩하고 드롭아웃 적용\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # LSTM에 임베딩 벡터를 입력하여 출력과 은닉 상태 반환\n",
        "        output, hidden = self.lstm(embedded)\n",
        "\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "pvCKUpw8WqaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # 임베딩 층: 출력 단어를 임베딩 벡터로 변환\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # LSTM 층: 임베딩 벡터를 입력으로 받아 디코딩\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "        # 완전 연결 층: LSTM의 출력을 출력 단어의 크기로 변환\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None, max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        # 첫 번째 디코더 입력을 <sos> 토큰으로 설정\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "\n",
        "        # 디코더 은닉 상태를 인코더 은닉 상태로 초기화\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # 디코더 출력을 저장할 리스트 초기화\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(max_length):\n",
        "            # 현재 타임스텝의 출력과 은닉 상태 계산\n",
        "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "\n",
        "            # 디코더 출력을 리스트에 저장\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            # teacher forcing 결정\n",
        "            if target_tensor is not None and random.random() < teacher_forcing_ratio:\n",
        "                # Teacher forcing: 목표 단어를 다음 입력으로 사용\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                # Teacher forcing 미사용: 예측 단어를 다음 입력으로 사용\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # 히스토리 추적을 분리\n",
        "\n",
        "        # 디코더 출력을 하나의 텐서로 결합\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "\n",
        "        # 출력에 로그 소프트맥스 적용\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, None  # 학습 루프의 일관성을 위해 `None` 반환\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        # 입력 단어를 임베딩하고 ReLU 활성화 함수 적용\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        # LSTM에 입력하고 출력과 은닉 상태 반환\n",
        "        output, hidden = self.lstm(output, hidden)\n",
        "\n",
        "        # 완전 연결 층을 통해 예측 단어로 변환\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "VDTUYT-IW72K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):\n",
        "        # 타겟 시퀀스의 길이 및 배치 크기, 출력 단어의 크기\n",
        "        trg_len = trg.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_size\n",
        "\n",
        "        # 디코더 출력을 저장할 텐서 초기화\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # 인코더를 통해 입력 시퀀스를 은닉 상태와 셀 상태로 변환\n",
        "        encoder_outputs, encoder_hidden = self.encoder(src)\n",
        "\n",
        "        # 첫 번째 디코더 입력을 <sos> 토큰으로 설정\n",
        "        decoder_input = trg[:, 0].unsqueeze(1)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # 현재 타임스텝의 출력과 은닉 상태 계산\n",
        "            decoder_output, decoder_hidden = self.decoder.forward_step(decoder_input, decoder_hidden)\n",
        "\n",
        "            # 디코더 출력을 텐서에 저장\n",
        "            outputs[:, t, :] = decoder_output.squeeze(1)\n",
        "\n",
        "            # teacher forcing 결정\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = decoder_output.argmax(2)\n",
        "\n",
        "            # 다음 입력을 teacher forcing에 따라 결정\n",
        "            decoder_input = trg[:, t].unsqueeze(1) if teacher_force else top1\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "3jTADev5XI0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 인코더 및 디코더 모델 정의\n",
        "encoder = EncoderRNN(INPUT_DIM, HID_DIM, ENC_DROPOUT)\n",
        "decoder = DecoderRNN(HID_DIM, OUTPUT_DIM)\n",
        "\n",
        "# Seq2Seq 모델 정의\n",
        "model_2 = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "# 모델 구조 출력\n",
        "print(model_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqdnu-STX9CQ",
        "outputId": "80dbe5ff-71c3-49d5-fc12-96d914e8dce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): EncoderRNN(\n",
            "    (embedding): Embedding(1000, 512)\n",
            "    (lstm): LSTM(512, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): DecoderRNN(\n",
            "    (embedding): Embedding(1000, 512)\n",
            "    (lstm): LSTM(512, 512, batch_first=True)\n",
            "    (out): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. 실제 데이터셋 사용 - 요약"
      ],
      "metadata": {
        "id": "X9XLLbnOaPar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "dataset_file_origin = 'https://www.gutenberg.org/cache/epub/1513/pg1513-images.html#sceneIII_30.1'\n",
        "\n",
        "# 요청을 보내고 응답을 받기\n",
        "response = requests.get(dataset_file_origin)\n",
        "\n",
        "# 응답이 성공적이면 파일로 저장\n",
        "if response.status_code == 200:\n",
        "    # 파일을 열고 데이터 쓰기\n",
        "    with open(\"romeo_and_juliet.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(response.text)\n",
        "    print(\"파일이 성공적으로 다운로드되었습니다.\")\n",
        "else:\n",
        "    print(f\"파일 다운로드 실패: 상태 코드 {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2-iGAhQaRoI",
        "outputId": "606292d4-9e82-4fb7-db83-278dfb627e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 성공적으로 다운로드되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "with open(\"romeo_and_juliet.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5L8P8voaVEi",
        "outputId": "0c5f0b51-ae23-4cf5-8d9e-047f02f1ed65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "<meta charset=\"utf-8\"><style>\n",
            "#pg-header div, #pg-footer div\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 - html tag 제거\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 읽어온 텍스트를 BeautifulSoup 객체로 변환\n",
        "soup = BeautifulSoup(text, 'html.parser')\n",
        "\n",
        "# p 태그 중 class가 drama인 태그 선택\n",
        "drama_paragraphs = soup.find_all('p', class_='drama')\n",
        "\n",
        "# 텍스트 추출\n",
        "cleaned_text = \"\"\n",
        "for para in drama_paragraphs:\n",
        "    cleaned_text += para.get_text(separator=\"\\n\") + \"\\n\"\n",
        "\n",
        "# 불필요한 공백 제거\n",
        "cleaned_text = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_text.strip())\n",
        "\n",
        "# 결과 출력 (일부만 출력)\n",
        "print(cleaned_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH7QwD5daVx8",
        "outputId": "d6707bc6-3e79-441e-d5b6-978d8472d6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESCALUS, Prince of Verona.\n",
            "\n",
            "MERCUTIO, kinsman to the Prince, and friend to Romeo.\n",
            "\n",
            "PARIS, a young Nobleman, kinsman to the Prince.\n",
            "\n",
            "Page to Paris.\n",
            "\n",
            "MONTAGUE, head of a Veronese family at feud with the Capulets.\n",
            "\n",
            "LADY MONTAGUE, wife to Montague.\n",
            "\n",
            "ROMEO, son to Montague.\n",
            "\n",
            "BENVOLIO, nephew to Montague, and friend to Romeo.\n",
            "\n",
            "ABRAM, servant to Montague.\n",
            "\n",
            "BALTHASAR, servant to Romeo.\n",
            "\n",
            "CAPULET, head of a Veronese family at feud with the Montagues.\n",
            "\n",
            "LADY CAPULET, wife to Capulet.\n",
            "\n",
            "JULIET, daughter to Capulet.\n",
            "\n",
            "TYBALT, nephew to Lady Capulet.\n",
            "\n",
            "CAPULET’S COUSIN, an old man.\n",
            "\n",
            "NURSE to Juliet.\n",
            "\n",
            "PETER, servant to Juliet’s Nurse.\n",
            "\n",
            "SAMPSON, servant to Capulet.\n",
            "\n",
            "GREGORY, servant to Capulet.\n",
            "\n",
            "Servants.\n",
            "\n",
            "FRIAR LAWRENCE, a Franciscan.\n",
            "\n",
            "FRIAR JOHN, of the same Order.\n",
            "\n",
            "An Apothecary.\n",
            "\n",
            "CHORUS.\n",
            "\n",
            "Three Musicians.\n",
            "\n",
            "An Officer.\n",
            "\n",
            "Citizens of Verona; several Men and Women, relations to both\n",
            "houses; Maskers, Guards, Watchmen and Attendants.\n",
            "\n",
            "CHORUS.\n",
            "\n",
            "Two households, both alike in dignity,\n",
            "\n",
            "In fair Verona, where we\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "chars = sorted(list(set(cleaned_text)))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "K50Mv3SPaZsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 데이터 생성 함수 정의\n",
        "def create_sequences(text, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(text) - seq_length):\n",
        "        seq = text[i:i+seq_length]   # 시퀀스 생성\n",
        "        target = text[i+seq_length]  # 시퀀스 다음에 오는 문자\n",
        "        sequences.append([char_to_idx[char] for char in seq])\n",
        "        targets.append(char_to_idx[target])\n",
        "    return sequences, targets"
      ],
      "metadata": {
        "id": "oounEtTkaa9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 길이 설정\n",
        "seq_length = 100\n",
        "\n",
        "# 시퀀스 데이터 생성\n",
        "sequences, targets = create_sequences(cleaned_text, seq_length)"
      ],
      "metadata": {
        "id": "Pwn1sAxoacTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXMR8pBaadoX",
        "outputId": "3e494057-5038-4185-d3c2-649d91fce93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13, 27, 11, 9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50], [27, 11, 9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37], [11, 9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47], [9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40], [20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48], [29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36], [27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49], [3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49, 3], [1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49, 3, 1], [24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49, 3, 1, 46]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Dataset 및 데이터로더 생성\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, sequences, targets, seq_length):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_seq = torch.tensor(self.sequences[idx], dtype=torch.long)\n",
        "        target_seq = torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "        return input_seq, target_seq"
      ],
      "metadata": {
        "id": "wcX-NR_TahAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 및 데이터로더 인스턴스 생성\n",
        "dataset = TextDataset(sequences, targets, seq_length)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "xH9s2v9OaiP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(chars)\n",
        "hidden_size = 256\n",
        "output_size = len(chars)\n",
        "num_layers = 2"
      ],
      "metadata": {
        "id": "HZJl9RIiajhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seq2Seq 모델 정의"
      ],
      "metadata": {
        "id": "dddn1O8iao_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, dropout=dropout_p)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.lstm(embedded)\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "EzYaCTlgaqvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        embedded = self.embedding(input)\n",
        "        embedded = F.relu(embedded)\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        output = self.out(output.squeeze(1))\n",
        "        return output, hidden, cell"
      ],
      "metadata": {
        "id": "0caP58pgawy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_size\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_output, (hidden, cell) = self.encoder(src)\n",
        "\n",
        "        input = trg[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[:, t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "YSOdRt4ba4bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(chars)\n",
        "hidden_size = 256\n",
        "output_size = len(chars)\n",
        "num_layers = 2\n",
        "dropout_p = 0.5\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "MAX_LENGTH = 100\n",
        "SOS_token = char_to_idx[' ']"
      ],
      "metadata": {
        "id": "dnl2l_tEcc9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 인코더 및 디코더 모델 초기화\n",
        "encoder = EncoderRNN(vocab_size, hidden_size, num_layers, dropout_p).to(device)\n",
        "decoder = DecoderRNN(hidden_size, vocab_size, num_layers).to(device)\n",
        "\n",
        "# Seq2Seq 모델 초기화\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "h7HG3Uw5cesu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for input_tensor, target_tensor in dataloader:\n",
        "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        target_tensor = target_tensor.unsqueeze(1).repeat(1, MAX_LENGTH)\n",
        "\n",
        "        output = model(input_tensor, target_tensor, teacher_forcing_ratio=0.5)\n",
        "\n",
        "        loss = criterion(output.view(-1, output_size), target_tensor.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1Nxs3ntckbF",
        "outputId": "5669bdf2-e85c-4761-c2a6-7f5414faf416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.1170\n",
            "Epoch 2, Loss: 0.0455\n",
            "Epoch 3, Loss: 0.0483\n",
            "Epoch 4, Loss: 0.0430\n",
            "Epoch 5, Loss: 0.0441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, start_char, char_to_idx, idx_to_char, max_length=100):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input = torch.tensor([char_to_idx[start_char]], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        _, (hidden, cell) = model.encoder(input)\n",
        "\n",
        "        input = input[:, -1].unsqueeze(1)\n",
        "        predicted_seq = start_char\n",
        "\n",
        "        for _ in range(max_length - 1):\n",
        "            output, (hidden, cell) = model.decoder(input, hidden, cell)\n",
        "            top1 = output.argmax(1)\n",
        "            char = idx2char[top1.item()]\n",
        "            predicted_seq += char\n",
        "            input = top1.unsqueeze(1)\n",
        "\n",
        "        return predicted_seq\n"
      ],
      "metadata": {
        "id": "6-8FaGdtcqAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 예제\n",
        "start_char = 'h'\n",
        "generated_text = predict(model, start_char, char_to_idx, idx_to_char, max_length=100)\n",
        "print(f'Generated text: {generated_text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "W9jfD9QbcsK_",
        "outputId": "c75711fe-c77f-4b2f-c0a2-2c82365bec54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'dim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b0521d95a172>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 예측 예제\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Generated text: {generated_text}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-0c2f1965fadb>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, start_char, char_to_idx, idx_to_char, max_length)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtop1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-40ec0fad4e22>\u001b[0m in \u001b[0;36mforward_step\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# LSTM에 입력하고 출력과 은닉 상태 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# 완전 연결 층을 통해 예측 단어로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                         msg = (\"For batched 3-D input, hx and cx should \"\n\u001b[1;32m    897\u001b[0m                                f\"also be 3-D but got ({hx[0].dim()}-D, {hx[1].dim()}-D) tensors\")\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dim'"
          ]
        }
      ]
    }
  ]
}