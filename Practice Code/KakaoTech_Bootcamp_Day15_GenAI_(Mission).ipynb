{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PnzaNV4a4HiR"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "dataset_file_origin = 'https://www.gutenberg.org/cache/epub/1513/pg1513-images.html#sceneIII_30.1'\n",
        "\n",
        "# 요청을 보내고 응답을 받기\n",
        "response = requests.get(dataset_file_origin)\n",
        "\n",
        "# 응답이 성공적이면 파일로 저장\n",
        "if response.status_code == 200:\n",
        "    # 파일을 열고 데이터 쓰기\n",
        "    with open(\"romeo_and_juliet.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(response.text)\n",
        "    print(\"파일이 성공적으로 다운로드되었습니다.\")\n",
        "else:\n",
        "    print(f\"파일 다운로드 실패: 상태 코드 {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ITlzeW24Oms",
        "outputId": "9503cff0-2e0f-4322-e47d-54bc5f70a894"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 성공적으로 다운로드되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "with open(\"romeo_and_juliet.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGwSBEaj5y3U",
        "outputId": "be5b349b-1891-4d80-b105-d937f80cdcc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "<meta charset=\"utf-8\"><style>\n",
            "#pg-header div, #pg-footer div\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 - html tag 제거\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 읽어온 텍스트를 BeautifulSoup 객체로 변환\n",
        "soup = BeautifulSoup(text, 'html.parser')\n",
        "\n",
        "# p 태그 중 class가 drama인 태그 선택\n",
        "drama_paragraphs = soup.find_all('p', class_='drama')\n",
        "\n",
        "# 텍스트 추출\n",
        "cleaned_text = \"\"\n",
        "for para in drama_paragraphs:\n",
        "    cleaned_text += para.get_text(separator=\"\\n\") + \"\\n\"\n",
        "\n",
        "# 불필요한 공백 제거\n",
        "cleaned_text = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_text.strip())\n",
        "\n",
        "# 결과 출력 (일부만 출력)\n",
        "print(cleaned_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXnfBGyo97ZN",
        "outputId": "4243d139-1e7b-4cef-f798-0a1111f0a776"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESCALUS, Prince of Verona.\n",
            "\n",
            "MERCUTIO, kinsman to the Prince, and friend to Romeo.\n",
            "\n",
            "PARIS, a young Nobleman, kinsman to the Prince.\n",
            "\n",
            "Page to Paris.\n",
            "\n",
            "MONTAGUE, head of a Veronese family at feud with the Capulets.\n",
            "\n",
            "LADY MONTAGUE, wife to Montague.\n",
            "\n",
            "ROMEO, son to Montague.\n",
            "\n",
            "BENVOLIO, nephew to Montague, and friend to Romeo.\n",
            "\n",
            "ABRAM, servant to Montague.\n",
            "\n",
            "BALTHASAR, servant to Romeo.\n",
            "\n",
            "CAPULET, head of a Veronese family at feud with the Montagues.\n",
            "\n",
            "LADY CAPULET, wife to Capulet.\n",
            "\n",
            "JULIET, daughter to Capulet.\n",
            "\n",
            "TYBALT, nephew to Lady Capulet.\n",
            "\n",
            "CAPULET’S COUSIN, an old man.\n",
            "\n",
            "NURSE to Juliet.\n",
            "\n",
            "PETER, servant to Juliet’s Nurse.\n",
            "\n",
            "SAMPSON, servant to Capulet.\n",
            "\n",
            "GREGORY, servant to Capulet.\n",
            "\n",
            "Servants.\n",
            "\n",
            "FRIAR LAWRENCE, a Franciscan.\n",
            "\n",
            "FRIAR JOHN, of the same Order.\n",
            "\n",
            "An Apothecary.\n",
            "\n",
            "CHORUS.\n",
            "\n",
            "Three Musicians.\n",
            "\n",
            "An Officer.\n",
            "\n",
            "Citizens of Verona; several Men and Women, relations to both\n",
            "houses; Maskers, Guards, Watchmen and Attendants.\n",
            "\n",
            "CHORUS.\n",
            "\n",
            "Two households, both alike in dignity,\n",
            "\n",
            "In fair Verona, where we\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "chars = sorted(list(set(cleaned_text)))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "G4YobFiz-gj2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 데이터 생성 함수 정의\n",
        "def create_sequences(text, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(text) - seq_length):\n",
        "        seq = text[i:i+seq_length]   # 시퀀스 생성\n",
        "        target = text[i+seq_length]  # 시퀀스 다음에 오는 문자\n",
        "        sequences.append([char_to_idx[char] for char in seq])\n",
        "        targets.append(char_to_idx[target])\n",
        "    return sequences, targets"
      ],
      "metadata": {
        "id": "Ou_fq9yd-lJM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 길이 설정\n",
        "seq_length = 100\n",
        "\n",
        "# 시퀀스 데이터 생성\n",
        "sequences, targets = create_sequences(cleaned_text, seq_length)"
      ],
      "metadata": {
        "id": "wo2eqXaq-nGM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fha-7h6M-oZu",
        "outputId": "1faaf8e2-243f-439f-e86d-9a3a663c36ba"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13, 27, 11, 9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50], [27, 11, 9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37], [11, 9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47], [9, 20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40], [20, 29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48], [29, 27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36], [27, 3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49], [3, 1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49, 3], [1, 24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49, 3, 1], [24, 53, 44, 49, 38, 40, 1, 50, 41, 1, 30, 40, 53, 50, 49, 36, 5, 0, 0, 21, 13, 26, 11, 29, 28, 17, 23, 3, 1, 46, 44, 49, 54, 48, 36, 49, 1, 55, 50, 1, 55, 43, 40, 1, 24, 53, 44, 49, 38, 40, 3, 1, 36, 49, 39, 1, 41, 53, 44, 40, 49, 39, 1, 55, 50, 1, 26, 50, 48, 40, 50, 5, 0, 0, 24, 9, 26, 17, 27, 3, 1, 36, 1, 60, 50, 56, 49, 42, 1, 22, 50, 37, 47, 40, 48, 36, 49, 3, 1, 46]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Dataset 및 데이터로더 생성\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.sequences[idx]), torch.tensor(self.targets[idx])"
      ],
      "metadata": {
        "id": "3M9Qa5Rt-vOe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 및 데이터로더 인스턴스 생성\n",
        "dataset = TextDataset(sequences, targets)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "IcLWc4N3_EzL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "vocab_size = len(chars)\n",
        "hidden_size = 256\n",
        "output_size = len(chars)\n",
        "num_layers = 2"
      ],
      "metadata": {
        "id": "BJfjaxBCCbTn"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LSTM 모델 구조 & 클래스 정의"
      ],
      "metadata": {
        "id": "jxn0I_KvCc7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, output_size, num_layers=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(vocab_size, hidden_size, num_layers, batch_first=True)  # RNN 레이어\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  # 완전 연결층\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.lstm(x, hidden)  # RNN 순전파\n",
        "        out = self.fc(out[:, -1, :])  # 마지막 시퀀스 출력만 사용\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # 초기 hidden state 설정\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        return (h0, c0)"
      ],
      "metadata": {
        "id": "TF3uf5pvCgiB"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 인스턴스 생성 및 GPU로 이동\n",
        "model = LSTMModel(vocab_size, hidden_size, output_size, num_layers).to(device)"
      ],
      "metadata": {
        "id": "QCm2CkntDXWd"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "u5foP24uDaoN"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 함수\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()  # 모델을 훈련 모드로 설정\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = nn.functional.one_hot(inputs, num_classes=vocab_size).float().to(device)  # 원-핫 인코딩 및 GPU로 이동\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            hidden = model.init_hidden(inputs.size(0))  # 각 배치마다 hidden 상태 초기화\n",
        "\n",
        "            # 옵티마이저 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 순전파, 역전파, 최적화\n",
        "            outputs, hidden = model(inputs, hidden)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # hidden 상태를 detach하여 그래프의 연결을 끊음\n",
        "            hidden = tuple([each.detach() for each in hidden])\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader):.4f}')\n",
        "\n",
        "    print('Finished Training')"
      ],
      "metadata": {
        "id": "BiXqObl9D1y2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_str, length, temperature=1.0):\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    hidden = model.init_hidden(1)  # 초기 hidden 상태 설정\n",
        "\n",
        "    input_seq = torch.tensor([char_to_idx[char] for char in start_str]).unsqueeze(0).to(device)\n",
        "    generated_text = start_str\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            input_seq = nn.functional.one_hot(input_seq, num_classes=vocab_size).float()\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "\n",
        "            # 다음 문자를 샘플링\n",
        "            output = output.squeeze().div(temperature).exp().cpu()\n",
        "            top_char = torch.multinomial(output, 1)[0]\n",
        "\n",
        "            generated_char = idx_to_char[top_char.item()]\n",
        "            generated_text += generated_char\n",
        "\n",
        "            # 다음 입력 시퀀스 준비\n",
        "            input_seq = torch.tensor([[top_char]]).to(device)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "6I6jRBw3E7b9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcJ8_NtyE9N1",
        "outputId": "ab11521f-60c3-40fa-c256-04b376365fd8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (lstm): LSTM(68, 256, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=256, out_features=68, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "train_model(model, dataloader, criterion, optimizer, num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Bl3A0BFBOV",
        "outputId": "ec41ee5b-303b-4be4-ab52-e1598f8949f3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 2.3542\n",
            "Epoch 2/5, Loss: 1.7890\n",
            "Epoch 3/5, Loss: 1.6006\n",
            "Epoch 4/5, Loss: 1.4865\n",
            "Epoch 5/5, Loss: 1.3980\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 시작 문자열 및 생성할 텍스트 길이\n",
        "start_str = \"To be, or not to be, that is the question:\"\n",
        "length = 200"
      ],
      "metadata": {
        "id": "ucDIcrsZFChQ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성\n",
        "generated_text = generate_text(model, start_str, length, temperature=0.8)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGFn3DJAFDYT",
        "outputId": "3ca3ac3a-3f84-49fb-aadb-9b84a933b62e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be, or not to be, that is the question:\n",
            "\n",
            "Thou hast, ring in the child!\n",
            "\n",
            "ROMEO.\n",
            "\n",
            "Then did is lade?—You denespity how a tears,\n",
            "\n",
            "The fair more marriage of the fiery\n",
            "\n",
            "In that do pirdor the poot sounds you, [\n",
            "fiely, behome,\n",
            "\n",
            "With tears no nothe\n"
          ]
        }
      ]
    }
  ]
}